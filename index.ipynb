{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# ROC Curves and AUC - Lab\n", "\n", "\n", "## Introduction \n", "\n", "In this lab, you'll practice drawing ROC graphs, calculating AUC, and interpreting these results. In doing so, you will also further review logistic regression, by briefly fitting a model as in a standard data science pipeline.\n", "\n", "## Objectives\n", "\n", "You will be able to:\n", "\n", "- Create a visualization of ROC curves and use it to assess a model \n", "- Evaluate classification models using the evaluation metrics appropriate for a specific problem "]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train the model\n", "\n", "Start by repeating the previous modeling steps we have discussed. For this problem, you are given a dataset `'mushrooms.csv'`. Your first job is to train a `LogisticRegression` classifier on the dataset to determine whether the mushroom is edible (e) or poisonous (p). The first column of the dataset `class` indicates whether or not the mushroom is poisonous or edible.\n", "\n", "But first, \n", "\n", "- Import the data \n", "- Print the first five rows of the data \n", "- Print DataFrame's `.info()` "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Import and preview the data\n", "\n", "\n", "df = None\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The next step is to define the predictor and target variables. Did you notice all the columns are of type `object`? So you will need to first create dummy variables. \n", "\n", "- First, create a dummy variable for the `'class'` column. Make sure you drop the first level \n", "- Drop the `'class'` column from `df` and then create dummy variables for all the remaining columns. Again, make sure you drop the first level \n", "- Import `train_test_split` \n", "- Split the data (`X` and `y`) into training and test sets with 25% in the test set. Set `random_state` to 42 to ensure reproducibility "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Define y\n", "y = None\n", "y = y['p']\n", "\n", "# Define X\n", "X = None\n", "X = None\n", "\n", "# Import train_test_split\n", "\n", "\n", "# Split the data into training and test sets\n", "X_train, X_test, y_train, y_test = None"]}, {"cell_type": "markdown", "metadata": {}, "source": ["- Fit the vanilla logistic regression model we defined for you to training data \n", "- Make predictions using this model on test data "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Import LogisticRegression\n", "from sklearn.linear_model import LogisticRegression\n", "\n", "# Instantiate\n", "logreg = LogisticRegression(fit_intercept=False, C=1e12, solver='liblinear')\n", "\n", "# Fit the model to training data\n", "model_log = None\n", "\n", "# Predict on test set\n", "y_hat_test = None"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Calculate TPR and FPR\n", "  \n", "Next, calculate the false positive rate and true positive rate (you can use the built-in functions from `sklearn`): "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Import roc_curve, auc\n", "\n", "\n", "# Calculate the probability scores of each point in the training set\n", "y_train_score = None\n", "\n", "# Calculate the fpr, tpr, and thresholds for the training set\n", "train_fpr, train_tpr, thresholds = None\n", "\n", "# Calculate the probability scores of each point in the test set\n", "y_score = None\n", "\n", "# Calculate the fpr, tpr, and thresholds for the test set\n", "fpr, tpr, thresholds = None"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Draw the ROC curve\n", "\n", "Next, use the false positive rate and true positive rate to plot the Receiver Operating Characteristic Curve for both the train and test sets."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "%matplotlib inline\n", "\n", "# Seaborn's beautiful styling\n", "sns.set_style('darkgrid', {'axes.facecolor': '0.9'})\n", "\n", "# ROC curve for training set\n", "plt.figure(figsize=(10, 8))\n", "lw = 2\n", "plt.plot(train_fpr, train_tpr, color='darkorange',\n", "         lw=lw, label='ROC curve')\n", "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n", "plt.xlim([0.0, 1.0])\n", "plt.ylim([0.0, 1.05])\n", "plt.yticks([i/20.0 for i in range(21)])\n", "plt.xticks([i/20.0 for i in range(21)])\n", "plt.xlabel('False Positive Rate')\n", "plt.ylabel('True Positive Rate')\n", "plt.title('Receiver operating characteristic (ROC) Curve for Training Set')\n", "plt.legend(loc='lower right')\n", "print('AUC: {}'.format(auc(train_fpr, train_tpr)))\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# ROC curve for test set\n", "plt.figure(figsize=(10, 8))\n", "lw = 2\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["What do you notice about these ROC curves? Your answer here: "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## Interpret ROC curves\n", "\n", "Since the mushroom model is atypically perfect, let's consider another dataset to practice interpreting ROC curves. This heart disease [dataset](https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset) is widely used in machine learning and a csv file of the data is in the GitHub repository.\n", "\n", "Look at the the heart disease's model ROC curve:  \n", "\n", "<img src=\"images/lesson_roc_graph.png\">\n", "\n", "Think about the scenario of this model: predicting heart disease. If you tune the current model to have an 82% True Positive Rate, (you've still missed 18% of those with heart disease), what is the False positive rate? "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Write the approximate fpr when tpr = 0.8\n", "fpr = None"]}, {"cell_type": "markdown", "metadata": {}, "source": ["If you instead tune the model to have a 95.2% True Postive Rate, what will the False Postive Rate be?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Write the approximate fpr when tpr = 0.95\n", "fpr = None"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In the case of heart disease dataset, do you find any of the above cases acceptable? How would you tune the model? Describe what this would mean in terms of the number of patients falsely scared of having heart disease and the risk of missing the warning signs for those who do actually have heart disease.\n", "\n", "Your answer here: "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["## Summary\n", "\n", "In this lab you further explored ROC curves and AUC, drawing graphs and then interpreting these results to lead to a more detailed and contextualized understanding of your model's accuracy."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.5"}}, "nbformat": 4, "nbformat_minor": 2}